{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(c): Betingede sannsynligheter og diskriminering\n",
    "\n",
    "Vi bruker de følgende forkortelser for hendelser:\n",
    "\n",
    "$R \\sim \\text{'Individet residiverer'}$\n",
    "\n",
    "$C \\sim \\text{'Individet har prediksjon HIGH av COMPAS'}$\n",
    "\n",
    "$A \\sim \\text{'Individet er etnisk afroamerikaner'}$\n",
    "\n",
    "$E \\sim \\text{'Individet er etnisk europeisk eller nord-afrikansk/\"caucasian\"'}$\n",
    "\n",
    "Når $A$ og $B$ er hendelser lar vi $\\neg A$, $A\\wedge B$ og $A \\vee B$ stå for henholdvis komplementhendelsen til $A$, unionhendelsen av $A$ og $B$ og disjunksjonhendelsen av $A$ og $B$. Sannsynligheten til en hendelse $A$ betegnes $P(A)$; den betingede sannsynligheten av en hendelse $A$ gitt en hendelse $B$ betegnes P(A\\mid B)\n",
    "\n",
    "Ett mulig mål på diskriminering av etnisk afro-amerikanere relativt til etnisk europeere, som foreslått av Henrik, er forholdstallet:\n",
    "\n",
    "$$D(A;E):=\\dfrac{P(C \\mid \\neg R \\wedge A)}{P(C \\mid \\neg R \\wedge E)},$$\n",
    "\n",
    "som er definert så lenge $P(C \\mid \\neg R \\wedge E)\\not=0$. Idéen bak dette målet er å sammenlikne sannsynlighetene for en predikert høy risiko av COMPAS blant etnisk afro-amerikanere som faktisk ikke residiverer og blant etnisk europeere som faktisk ikke residiverer. Jo høyere forholdet mellom disse to sannsynlighetene er, jo mer diskrimineres det mot etnisk afro-amerikanere relativt til etnisk europeere; dette sier hvertfall målet vårt over. \n",
    "\n",
    "Vi kan bruke Bayes teorem til å se en relasjon mellom dette målet diskiriminasjon og presisjonen til algoritmen innad i de to gruppene.\n",
    "\n",
    "Målet vi har over er sannsynligvis ikke et godt mål på diskriminasjon i prediksjoner. Her er en intuitiv forklaring på hvorfor: Dersom én gruppe har høyere sannsynlighet for å residivere enn en annen, så kan uten å diskriminere predikere at den ene gruppen residiverer oftere enn den andre gruppen. Men selv om raten av falske positive blant positive prediskjoner er den samme i begge tilfeller, vil man kunne ha høyere sannsynlighet for falske positive i den ene mer residiverende gruppen enn den andre. Målet over dømmer dermed en slik algoritme for diskriminerende selv om algoritmen intuitivt ikke er diskriminerende. \n",
    "\n",
    "Et konkret eksempel er som følger. Vi har en populasjon med 2000 individer hvor vi har to grupper $E$ og $A$ hvor residivering og prediksjonene er som følger: \n",
    "\n",
    " $Totalt$; $R$;  $C$; $C\\wedge R$        \n",
    " \n",
    " $E:$           $1000$;    $500;$       $500;$ $250$\n",
    " \n",
    " $A:$           $1000;$    $250;$     $250;$          $125$\n",
    "\n",
    "Denne (unøyaktige) prediksjonsalgoritmen kan man argumentere for at ikke er diskriminerende: den predikerer en persons risiko på bakgrunn av residiveringsraten for den personens etniske gruppe; ingen av gruppene har urettferdig høy unøyaktighet i prediksjonene. (Om du ikke ønsker å predikere ved hjelp av etnisk gruppe kan du omformulere eksempelet slik at prediksjonen blir gjort utelukkende på bakgrunn av en annen variabel, her f. eks. fattigdom, som korrelerer med den ene etnisitetsvariabelen.)\n",
    "\n",
    "Men målet over sier dette er en svært diskriminerende prediksjon:\n",
    "\n",
    "$$P(C \\mid \\neg R \\wedge E)=\\frac{125}{750}=\\frac{5}{30}$$\n",
    "$$P(C \\mid \\neg R \\wedge A)=\\frac{250}{500}=\\frac{1}{2}$$\n",
    "\n",
    "Ifølge målet over diskriminerer derfor prediksjonen sterkt imot $E$ relativt til $A$, selv om dette intuitivt ikke er riktig: gruppen $E$ har mye høyere residiveringsrate, som er grunnen til at det predikeres oftere at individer av gruppen $E$ vil residivere, som er grunnen til at flere ikke-residiverende $E$-er får en falsk positiv prediksjon.\n",
    "\n",
    "Et par mål som ikke lider av dette problemet er de følgende. Først, et mål på forskjell i rate av falske positive: \n",
    "\n",
    "$$D_+(A;E):=\\dfrac{P(\\neg R \\mid C \\wedge A)}{P(\\neg R \\mid C \\wedge E)},$$\n",
    "\n",
    "Annet, et mål på forskjell i rate av falske negative: \n",
    "$$D_-(A;E):=\\dfrac{P( R \\mid \\neg C \\wedge A)}{P( R \\mid \\neg C \\wedge E)}.$$\n",
    "\n",
    "Merk at disse målene er uavhengige av hverandre: en gruppe som har høyere (lavere) falsk positiv rate enn en annen gruppe kan ha høyere og kan ha lavere falsk negativ rate enn den andre gruppen. \n",
    "\n",
    "Ett mulig krav på at en algoritme skal være ikke-diskriminerende kan være at den har ingen eller lav grad av både falsk positiv og falsk negativ diskriminering. I dette tilfellet kommer dette kravet til at (når de kondisjonelle sannsynlighetene er definerte):\n",
    "\n",
    "$$P(\\neg R \\mid C \\wedge A)=P(\\neg R \\mid C \\wedge E)\\text{, og}$$\n",
    "\n",
    "$$P( R \\mid \\neg C \\wedge A)=P( R \\mid \\neg C \\wedge E).$$\n",
    "\n",
    "La oss se at disse målene ikke lider av problemet vi hadde med det forrige målet. Ta eksempelet vi brukte med populasjonen av 2000 over. Da har vi at prediksjonen ikke er diskriminerende, altså den tilfredstiller betingelsene over. For eksempel, i tilfellet for rate av falsk positiv har vi ingen forskjell, altså ingen diskriminering:\n",
    "\n",
    "$$P(\\neg R \\mid C \\wedge A)=\\dfrac{125}{250}=\\dfrac{1}{2}=\\dfrac{250}{500}=P( \\neg R \\mid C \\wedge E).$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
