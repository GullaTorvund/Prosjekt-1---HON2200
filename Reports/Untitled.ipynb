{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et domene hvor det er blitt mulig å anvende maskinlæringsalgoritmer er i trekkingen av rettslige beslutninger. En spesifikk slik anvendelse er for å assistere i å gi risikoestimat for kriminelt tilbakefall, residivering, blant kriminelle. Slike anvendelser har vært i bruk, blant annet ble en slik algoritme, COMPAS-algoritmen, anvendt i Florida på 2010-tallet. I 2016 undersøkte det amerikanske tidsskriftet ProPublica en analyse av bruken av COMPAS-algoritmen, og fremmet anklage om at algoritmen hadde et diskriminerende bias.\n",
    "\n",
    "I denne rapporten gjennomfører vi en analyse av COMPAS-algoritmen liknende den utført av ProPublica-studien. Målet er å undersøke hvorvidt og i hvilken grad COMPAS-algoritmen diskriminerer på bakgrunn av rase. Planen for oppgaven er som følger. I seksjon [2](#2) (1a og 1b) gjør vi en enkel dataanalyse og sammenlikning av rater for faktisk residivering og predikert residivering innad i forskjellige grupper av befolkningen. I seksjon [3](#3) (1d) studerer vi beslutningene til COMPAS-algoritmen ved å trene en logistisk regresjonsmodell som predikerer COMPAS' avgjørelser på basis av, blant annet, rase og kjønn. Fra vår modell henter vi ut et mål, partial dependence, på hvor mye vekt COMPAS-algoritmen legger på rase-variabelen. I seksjon [4](#4) diskuterer vi probabilistike mål på grad av diskriminering. I seksjon [5](#5) diskuterer vi funnnene våre og argumenterer for at disse viser at COMPAS-algoritmen diskriminerer på basis av rase. Seksjon [6](#6) konkluderer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dersom det er systematiske forskjeller mellom grupper i et samfunn og dette fører til eller henger sammen med økt kriminalitet i enkelte grupper, så gir det mening å ta dette i betraktning når man skal forsøke å hindre kriminalitet. Ideelt sett så vil alle grupper i samfunnet være så integrerte og tilpasset hverandre at gruppetilhørighet, faktisk eller tenkt, ikke vil ha noe å si for økonomiske og sosiale forhold, og at kriminalitet vil være jevnt fordelt. I fraværet av en slik ideell tilstand så vil det være urettferdig ikke å ta stilling til gruppe, nettopp fordi det er viktig for å predikere hvem som residiverer og for at man skal kunne fange det opp dersom systemet er med på å holde gruppeforskjellene som fører til kriminalitet ved like. Ideelt sett har ikke gruppe noe å si, men det kan være hensiktsmessig med tanke på et formål om å hindre kriminalitet, å ta stilling til gruppetilhørighet dersom det viser seg å være en viktig faktor.\n",
    " \n",
    "*Men så kan man spørre seg om det faktisk er slik at noen tilhører en gruppe bare fordi de har en etnisitet. Må kanskje skille på etnisitet og rase.* \n",
    "\n",
    "Vi har definert et mål på gruppediskriminering i [del 4](#4) som tilsier at algoritmen ikke kan gi fordeler basert på hvilken gruppe du tilhører. Det vil si at uavhengig av hvor mye kriminalitet det er i en gitt gruppe så må algoritmen ta like mye feil av hvem som kommer til å residivere og ikke residivere i hver gruppe. Dersom dette målet er tilfredsstilt så er det grunn til å si at algoritmen ikke gir fordeler eller ulemper basert på gruppe og derfor ikke diskriminerer mellom gruppene. Altså at det er like høy rate av de som blir sittende inne selv om de ikke residiverer og at det er like høy rate av de som slipper ut av fengsel som residiverer uavhengig av hvilken gruppe man ser på. *Du er like sannsynlig å havne innenfor feilmarginen uansett hvilken gruppe du tilhører*(?)\n",
    "    \n",
    "Vi ser at det er nesten helt like falsk positiv rater mellom kvinner og menn noe som vil tilsi at det er like sannsynlig å få en høy COMPAS Score selv om man ikke kommer til å residivere, uavhengig av kjønn. Derimot er det noe større forskjell i falske negative (lavere rate for kvinner), som kan tilsi at kvinner har større sannsynlighet for å få lav Score og residivere enn menn, men forskjellen er liten.\n",
    "\n",
    "Når vi ser på falske positive mellom hvite og svarte ser det langt verre ut, svarte har mye større sannsynlighet for å få høy COMPAS Score, selv om de ikke residiverer, enn hvite som ikke residiverer. Ser man på falske negative er forskjellen tilsvarende urettferdig, med langt høyere falsk negativ rate for hvite, er det mer sannsynlig at en hvit person får lav score og residiverer enn at en svart person får lav score og residiverer.\n",
    "\n",
    "Dersom COMPAS Score ligger til grunn for prøveløslatelser så vil man se at det er lettere for hvite enn for svarte å slippe ut selv om de kommer til å residivere. Det vil òg være flere svarte som får høy COMPAS Score selv om de ikke kommer til å residivere. Fordi prøveløslatelse er et gode som skal fordeles til de som er ufarlige for samfunnet, kan vi si at de som får tildelt prøveløslatelse og residiverer får tildelt dette godet urettmessig. En høy falsk positiv rate i en gruppe, vil tilsi at individer i denne gruppen lettere blir nektet prøveløslatelse selv om de trygt kunne sluppet ut. En høy falsk negativ rate i en gruppe vil peke på at individer i denne gruppen lettere får prøveløslatelse selv om de residiverer.  Det er da grunn til å tro at algoritmen er skjev i retning av å holde svarte i fengsel og lettere slippe hvite ut av fengsel.\n",
    "Partial dependence plottingen viser at det slår ut positivt på COMPAS Scoren dersom en person er svart, dvs. høyere sannsynlighet for å bli predikert til å residivere. Alene er det vanskelig å si at dette er et mål på diskriminering, men det er ubehagelig, og muligens rasistisk at rase skal spille en rolle i prediksjonen av hvem som residiverer og ikke. \n",
    "\n",
    "\n",
    "Funnene våre hva angår algoritmens behandling av kvinner viser seg å sprike, som nevnt kan det se ut som kvinner har en litt høyere falsk negativ rate enn menn som vil tilsi at en større andel kvinner som residiverer blir predikert til ikke å gjøre det. At i forhold til menn så vil algoritmen gjøre det lettere for kvinner å slippe ut av fengsel, selv om de ikke burde det. \n",
    "\n",
    "Men dette strider med andre funn vi har som kan tilsi at algoritmen diskriminerer kvinner negativt. En større prosentandel kvinner blir predikert til å residivere en de som faktisk gjør det, mens en lavere prosentandel av menn blir predikert til å residivere, en de som faktisk gjør det. Dette kan tolkes dit at algoritmen overvurderer andelen kvinner som residiverer og undervurderer andelen menn, uten at man har sett disse gruppene i sammenheng med hverandre. \n",
    "\n",
    "Et annet mål som kan peke på at kvinner diskrimineres imot er at i partial dependency plottet, så ser det ut til at algoritmen gir i snitt høyere score dersom personen som vurderes er en kvinne. \n",
    "\n",
    "Det er i sum vanskelig å vurdere om algoritmen er kvinne diskriminerende eller ikke, siden vi har funn som peker i begge rettninger. En kan dog si at siden det ikke er helt jevnt mellom menn og kvinner i alt at kjønn uansett ser ut til å spille en rolle og at den derfor er sexistisk. \n",
    "\n",
    "\n",
    "- referere til etikk-rapport\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
